Hey! Thanks for checking out my project! Why is it called Chessgle? I couldn't find a better name.

You play against the computer as white. You can start the game just by running the program and putting in moves. 
Moves are inputted with the UCI standard (ex: e2e4, g1f3, b1c3). 

Rows are documented with numbers 1 through 8.
Letters are documented with letters a through h.

First letter and number represent the "from" square, and the second letter and number represent the "to" square. 
They make up a MOVE.

Explanation:
My AP CS final program consists of two parts: the mailbox implementation, made with 2d arrays, and the standard Negamax DFS search, coupled with Alpha-Beta pruning and classic HCE for static evaluation. There isn’t much to say about the mailbox implementation as it is pretty standard. I first worked on defining checks and then legal move generation. It is a complete chess board representation with the ability to parse a FEN string, castle, and En Passant. I will admit that, however, it is pretty inefficient since it isn’t written with bitboards, but I believe that this implementation suffices for a project of this scale, and my skill set isn’t sharp enough for something of that complexity. Thus, the engine that I wrote for it is equally as weak; however, it gives a decent play against anyone who challenges it, so I am satisfied with the results.

The engine only uses three things for its search: Negamax DFS Search, Alpha-Beta pruning, and QSearch, short for Quiescence Search. Negamax is a variant of Minimax, which makes implementation go a lot smoother for the dev. While Minimax keeps track of a maximizing and minimizing player, Negamax flips the values along each ply, which is the distance from the root position. Thus, we can assume that the opposing player is the minimizer when writing the implementation instead of hardcoding flipped implementations for both the maximizer and the minimizer. 

QSearch is an extension to the Negamax algorithm, which ensures that positions where the tree terminates are stable, fixing the horizon effect that would otherwise most definitely occur. Say that the engine is to search at a depth of six and that at depth of 0 it takes a pawn with a queen. That is excellent as it gains material; however, lurking behind that termination, there could be a pawn move to take that queen back, which the engine cannot evaluate as it is coded to only evaluate that specified depth of N. The QSearch operates with no depth restriction on only searching down captures since they are the most likely to cause an unsafe position that creates a horizon effect. Despite the removal of non-capture moves, 90% of nodes in the search tree are calculated in this section. Within each node of the QSearch, we would call on the static evaluation and assign it to a variable called “standPat.” Then, we would proceed with a hopeful beta-cutoff fail-hard termination, checking for whether the standPat is greater or equal to beta, and otherwise raising alpha if it does not fail high on this check. After raising the alpha, we would then generate all loud moves for the position and then check for its length. If the length is zero, that means that there are no captures in the move, signifying that it is a stable position to terminate on, making it safe to return the standPat, a fail-soft as it could be outside the alpha-beta window. This essentially replaces the depth == 0 check that would otherwise occur in the regular Negamax search.

Alpha-Beta pruning is a tougher concept where it acts on the knowledge of what the opposing player will pick if played optimally and it is the backbone of all strong chess engines like Stockfish. All other extensions, reductions, and pruning methods usually act on the idea of Alpha-Beta. Alpha is the lower bound. It is the minimum score that a move needs to generate for it to be set as the best move of the position. Beta is the upper bound. It is the maximum score that a node can reach before it and all the following right-leaning children can be exempted from checking, as it is based on what the opposing player, which can be seen as the minimizer, will definitely pick. A beta cutoff occurs when alpha is greater or equal to beta. We can safely ensure that we can prune all branches left in a node if just one of them fulfills this conditional since everything from this point on forwards will definitely not be picked by the minimizer, the opposing player, and everything less than this move will not be played by yourself since it fails-low on an alpha check as we do not want to pick moves worse than the best one we’ve found so far. Say that our parent node, the minimizer, has your left-leaning sibling node set to the value of 4. That value will be passed down to our current node as beta. If our best move exceeds or equals the value of 4 we know that our parent node will not pick it since the minimizer will always pick the smallest value, and any value lower than 4 will not be picked by us since we do not want to pick worse moves, which is now defined by alpha. 

My static evaluation is a HCE, short for Hand Crafted Evaluation. It is rather simple. It takes a position, finds all the pieces for both sides of the board, and sums up a score for each side based on the piece value and piece position. The Piece Value, also known as Piece Weights, are found off the Chess Programming Wiki, as well as the Piece Position tables, also known as PSTs.
https://www.google.com/url?q=https://www.chessprogramming.org/Simplified_Evaluation_Function&sa=D&source=docs&ust=1670620090136009&usg=AOvVaw2fQGFzPSy537Jtl7zuHNds

Fail-High: Score compared with the value is greater or equal to it
Fail-Low: Score compares with the value is less or equal to it
Fail-Soft: Returning the score that is outside the alpha-beta windows on fail high or fail low checks
Fail-Hard: Returning the bound that the score is compared with on fail high or fail low checks as a definitive lower or upper bound for the position (Fail High would return a lower bound; Fail Low would return an upper bound)
